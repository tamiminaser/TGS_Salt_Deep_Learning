{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout\n",
    "from tqdm import tqdm_notebook\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "#pd.set_option('display.max_colwidth',50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 4) (18000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_Image_path</th>\n",
       "      <th>Train_Mask_path</th>\n",
       "      <th>id</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./train/images/44381a3f55.png</td>\n",
       "      <td>./train/masks/44381a3f55.png</td>\n",
       "      <td>44381a3f55</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./train/images/70db04a203.png</td>\n",
       "      <td>./train/masks/70db04a203.png</td>\n",
       "      <td>70db04a203</td>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./train/images/42c563d895.png</td>\n",
       "      <td>./train/masks/42c563d895.png</td>\n",
       "      <td>42c563d895</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./train/images/d422a9eb8f.png</td>\n",
       "      <td>./train/masks/d422a9eb8f.png</td>\n",
       "      <td>d422a9eb8f</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./train/images/6d4fca6a35.png</td>\n",
       "      <td>./train/masks/6d4fca6a35.png</td>\n",
       "      <td>6d4fca6a35</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Train_Image_path               Train_Mask_path          id  \\\n",
       "0  ./train/images/44381a3f55.png  ./train/masks/44381a3f55.png  44381a3f55   \n",
       "1  ./train/images/70db04a203.png  ./train/masks/70db04a203.png  70db04a203   \n",
       "2  ./train/images/42c563d895.png  ./train/masks/42c563d895.png  42c563d895   \n",
       "3  ./train/images/d422a9eb8f.png  ./train/masks/d422a9eb8f.png  d422a9eb8f   \n",
       "4  ./train/images/6d4fca6a35.png  ./train/masks/6d4fca6a35.png  6d4fca6a35   \n",
       "\n",
       "     z  \n",
       "0   73  \n",
       "1  776  \n",
       "2  505  \n",
       "3  662  \n",
       "4  443  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_Image_folder='./train/images/'\n",
    "Train_Mask_folder='./train/masks/'\n",
    "Test_Image_folder='./test/'\n",
    "Train_Image_name=os.listdir(path=Train_Image_folder)\n",
    "Test_Image_name=os.listdir(path=Test_Image_folder)\n",
    "Train_Image_path=[]\n",
    "Train_Mask_path=[]\n",
    "Train_id=[]\n",
    "for i in Train_Image_name:\n",
    "    path1=Train_Image_folder+i\n",
    "    path2=Train_Mask_folder+i\n",
    "    id1=i.split(sep='.')[0]\n",
    "    Train_Image_path.append(path1)\n",
    "    Train_Mask_path.append(path2)\n",
    "    Train_id.append(id1)\n",
    "  \n",
    "\n",
    "Test_Image_path=[]\n",
    "Test_id=[]\n",
    "for i in Test_Image_name:\n",
    "    path=Test_Image_folder+i\n",
    "    id2=i.split(sep='.')[0]\n",
    "    Test_Image_path.append(path)\n",
    "    Test_id.append(id2)\n",
    "    \n",
    "df_Train_path=pd.DataFrame({'id':Train_id,'Train_Image_path':Train_Image_path,'Train_Mask_path':Train_Mask_path})\n",
    "df_Test_path=pd.DataFrame({'id':Test_id,'Test_Image_path':Test_Image_path})\n",
    "\n",
    "df_depths=pd.read_csv('./depths.csv')\n",
    "df_sub=pd.read_csv('./sample_submission.csv')\n",
    "df_Train_path=df_Train_path.merge(df_depths,on='id',how='left')\n",
    "df_Test_path=df_Test_path.merge(df_depths,on='id',how='left')\n",
    "df_Test_path=df_sub.merge(df_Test_path,on='id',how='left')\n",
    "print(df_Train_path.shape,df_Test_path.shape)\n",
    "df_Train_path.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Test_Image_path</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>155410d6fa</td>\n",
       "      <td>./test/155410d6fa.png</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78b32781d1</td>\n",
       "      <td>./test/78b32781d1.png</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63db2a476a</td>\n",
       "      <td>./test/63db2a476a.png</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17bfcdb967</td>\n",
       "      <td>./test/17bfcdb967.png</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7ea0fd3c88</td>\n",
       "      <td>./test/7ea0fd3c88.png</td>\n",
       "      <td>837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        Test_Image_path    z\n",
       "0  155410d6fa  ./test/155410d6fa.png  559\n",
       "1  78b32781d1  ./test/78b32781d1.png  298\n",
       "2  63db2a476a  ./test/63db2a476a.png  392\n",
       "3  17bfcdb967  ./test/17bfcdb967.png  698\n",
       "4  7ea0fd3c88  ./test/7ea0fd3c88.png  837"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test_path.drop('rle_mask',axis=1,inplace=True)\n",
    "df_Test_path.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9daa3f7978d42f1b320d02e6d0eb3a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "674459010ebf4556ae01da5648b6fbe5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_Train_path[\"images\"] = [np.array(load_img(path=idx, grayscale=True)) / 255 for idx in tqdm_notebook(df_Train_path.Train_Image_path)]\n",
    "df_Train_path[\"masks\"]=[np.array(load_img(path=idx, grayscale=True)) / 255 for idx in tqdm_notebook(df_Train_path.Train_Mask_path)]\n",
    "df_Train_path[\"coverage\"] = df_Train_path.masks.map(np.sum) / pow(101, 2)\n",
    "def cov_to_class(val):    \n",
    "    for i in range(0, 11):\n",
    "        if val * 10 <= i :\n",
    "            return i\n",
    "        \n",
    "df_Train_path[\"coverage_class\"] = df_Train_path.coverage.map(cov_to_class)\n",
    "#df_Train_path.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_size_ori = 101\n",
    "img_size_target = 128\n",
    "\n",
    "def upsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
    "\n",
    "def downsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n",
    "    df_Train_path.id.values,\n",
    "    np.array(df_Train_path.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "    np.array(df_Train_path.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "    df_Train_path.coverage.values,\n",
    "    df_Train_path.z.values,\n",
    "    test_size=0.2, stratify=df_Train_path.coverage_class, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200,) (800,)\n",
      "(3200, 128, 128, 1) (3200, 128, 128, 1)\n",
      "(800, 128, 128, 1) (800, 128, 128, 1)\n",
      "(3200,) (800,)\n",
      "(3200,) (800,)\n"
     ]
    }
   ],
   "source": [
    "print(ids_train.shape,ids_valid.shape)\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_valid.shape,y_valid.shape)\n",
    "print(cov_train.shape,cov_test.shape)\n",
    "print(depth_train.shape,depth_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define IoU metric\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Another method\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(input_layer, start_neurons):\n",
    "    # 128 -> 64\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(input_layer)\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    pool1 = Dropout(0.25)(pool1)\n",
    "\n",
    "    # 64 -> 32\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    pool2 = Dropout(0.5)(pool2)\n",
    "\n",
    "    # 32 -> 16\n",
    "    conv3 = Conv2D(start_neurons * 4, (5, 5), activation=\"relu\", padding=\"same\")(pool2)\n",
    "    conv3 = Conv2D(start_neurons * 4, (5, 5), activation=\"relu\", padding=\"same\")(conv3)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    pool3 = Dropout(0.5)(pool3)\n",
    "\n",
    "    # 16 -> 8\n",
    "    conv4 = Conv2D(start_neurons * 8, (5, 5), activation=\"relu\", padding=\"same\")(pool3)\n",
    "    conv4 = Conv2D(start_neurons * 8, (5, 5), activation=\"relu\", padding=\"same\")(conv4)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = Dropout(0.5)(pool4)\n",
    "\n",
    "    # Middle\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(pool4)\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(convm)\n",
    "\n",
    "    # 8 -> 16\n",
    "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = Dropout(0.5)(uconv4)\n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n",
    "    #uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n",
    "\n",
    "    # 16 -> 32\n",
    "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    uconv3 = concatenate([deconv3, conv3])\n",
    "    uconv3 = Dropout(0.5)(uconv3)\n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n",
    "\n",
    "    # 32 -> 64\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "    uconv2 = Dropout(0.5)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n",
    "\n",
    "    # 64 -> 128\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, (3,3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    uconv1 = Dropout(0.5)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3,3), activation=\"relu\", padding=\"same\")(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3,3), activation=\"relu\", padding=\"same\")(uconv1)\n",
    "\n",
    "    uncov1 = Dropout(0.5)(uconv1)\n",
    "    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
    "    \n",
    "    return output_layer\n",
    "\n",
    "input_layer = Input((img_size_target, img_size_target, 1))\n",
    "output_layer = build_model(input_layer, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(input_layer, output_layer)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr=0.001), metrics=[mean_iou])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
    "y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 800 samples\n",
      "Epoch 1/80\n",
      "6400/6400 [==============================] - 995s 155ms/step - loss: 0.5608 - mean_iou: 0.3807 - val_loss: 0.5065 - val_mean_iou: 0.3819\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.50646, saving model to ./keras.model\n",
      "Epoch 2/80\n",
      "6400/6400 [==============================] - 963s 151ms/step - loss: 0.4569 - mean_iou: 0.3887 - val_loss: 0.4119 - val_mean_iou: 0.4127\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.50646 to 0.41194, saving model to ./keras.model\n",
      "Epoch 3/80\n",
      "6400/6400 [==============================] - 985s 154ms/step - loss: 0.3823 - mean_iou: 0.4414 - val_loss: 0.3451 - val_mean_iou: 0.4651\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.41194 to 0.34510, saving model to ./keras.model\n",
      "Epoch 4/80\n",
      "6400/6400 [==============================] - 1004s 157ms/step - loss: 0.3505 - mean_iou: 0.4832 - val_loss: 0.2937 - val_mean_iou: 0.5025\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.34510 to 0.29372, saving model to ./keras.model\n",
      "Epoch 5/80\n",
      "6400/6400 [==============================] - 1007s 157ms/step - loss: 0.3033 - mean_iou: 0.5201 - val_loss: 0.2799 - val_mean_iou: 0.5364\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.29372 to 0.27992, saving model to ./keras.model\n",
      "Epoch 6/80\n",
      "6400/6400 [==============================] - 1042s 163ms/step - loss: 0.2736 - mean_iou: 0.5521 - val_loss: 0.2574 - val_mean_iou: 0.5660\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.27992 to 0.25739, saving model to ./keras.model\n",
      "Epoch 7/80\n",
      "6400/6400 [==============================] - 1012s 158ms/step - loss: 0.2592 - mean_iou: 0.5779 - val_loss: 0.2439 - val_mean_iou: 0.5890\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.25739 to 0.24390, saving model to ./keras.model\n",
      "Epoch 8/80\n",
      "6400/6400 [==============================] - 1022s 160ms/step - loss: 0.2473 - mean_iou: 0.5985 - val_loss: 0.3524 - val_mean_iou: 0.6054\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/80\n",
      "6400/6400 [==============================] - 990s 155ms/step - loss: 0.2447 - mean_iou: 0.6101 - val_loss: 0.2445 - val_mean_iou: 0.6178\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/80\n",
      "6400/6400 [==============================] - 982s 153ms/step - loss: 0.2259 - mean_iou: 0.6248 - val_loss: 0.2288 - val_mean_iou: 0.6315\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.24390 to 0.22878, saving model to ./keras.model\n",
      "Epoch 11/80\n",
      "6400/6400 [==============================] - 961s 150ms/step - loss: 0.2074 - mean_iou: 0.6382 - val_loss: 0.2153 - val_mean_iou: 0.6440\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.22878 to 0.21529, saving model to ./keras.model\n",
      "Epoch 12/80\n",
      "6400/6400 [==============================] - 955s 149ms/step - loss: 0.2035 - mean_iou: 0.6498 - val_loss: 0.2116 - val_mean_iou: 0.6543\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.21529 to 0.21160, saving model to ./keras.model\n",
      "Epoch 13/80\n",
      "6400/6400 [==============================] - 955s 149ms/step - loss: 0.2011 - mean_iou: 0.6586 - val_loss: 0.2140 - val_mean_iou: 0.6630\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/80\n",
      "6400/6400 [==============================] - 960s 150ms/step - loss: 0.1879 - mean_iou: 0.6675 - val_loss: 0.1957 - val_mean_iou: 0.6716\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.21160 to 0.19573, saving model to ./keras.model\n",
      "Epoch 15/80\n",
      "6400/6400 [==============================] - 964s 151ms/step - loss: 0.1941 - mean_iou: 0.6755 - val_loss: 0.2002 - val_mean_iou: 0.6786\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/80\n",
      "6400/6400 [==============================] - 965s 151ms/step - loss: 0.1796 - mean_iou: 0.6821 - val_loss: 0.1843 - val_mean_iou: 0.6854\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.19573 to 0.18428, saving model to ./keras.model\n",
      "Epoch 17/80\n",
      "6400/6400 [==============================] - 965s 151ms/step - loss: 0.1746 - mean_iou: 0.6887 - val_loss: 0.1824 - val_mean_iou: 0.6916\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.18428 to 0.18236, saving model to ./keras.model\n",
      "Epoch 18/80\n",
      "6400/6400 [==============================] - 967s 151ms/step - loss: 0.1733 - mean_iou: 0.6945 - val_loss: 0.2243 - val_mean_iou: 0.6972\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/80\n",
      "6400/6400 [==============================] - 966s 151ms/step - loss: 0.1790 - mean_iou: 0.6997 - val_loss: 0.1928 - val_mean_iou: 0.7022\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/80\n",
      "6400/6400 [==============================] - 968s 151ms/step - loss: 0.1642 - mean_iou: 0.7049 - val_loss: 0.1776 - val_mean_iou: 0.7072\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.18236 to 0.17761, saving model to ./keras.model\n",
      "Epoch 21/80\n",
      "6400/6400 [==============================] - 968s 151ms/step - loss: 0.1660 - mean_iou: 0.7093 - val_loss: 0.1929 - val_mean_iou: 0.7116\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/80\n",
      "6400/6400 [==============================] - 968s 151ms/step - loss: 0.1655 - mean_iou: 0.7137 - val_loss: 0.1822 - val_mean_iou: 0.7159\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/80\n",
      "6400/6400 [==============================] - 970s 152ms/step - loss: 0.1591 - mean_iou: 0.7179 - val_loss: 0.1776 - val_mean_iou: 0.7199\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/80\n",
      "6400/6400 [==============================] - 971s 152ms/step - loss: 0.1593 - mean_iou: 0.7219 - val_loss: 0.1842 - val_mean_iou: 0.7237\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/80\n",
      "6400/6400 [==============================] - 970s 152ms/step - loss: 0.1539 - mean_iou: 0.7253 - val_loss: 0.1808 - val_mean_iou: 0.7270\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/80\n",
      "6400/6400 [==============================] - 970s 151ms/step - loss: 0.1496 - mean_iou: 0.7286 - val_loss: 0.1812 - val_mean_iou: 0.7303\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 27/80\n",
      "6400/6400 [==============================] - 974s 152ms/step - loss: 0.1313 - mean_iou: 0.7322 - val_loss: 0.1723 - val_mean_iou: 0.7341\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.17761 to 0.17232, saving model to ./keras.model\n",
      "Epoch 28/80\n",
      "6400/6400 [==============================] - 975s 152ms/step - loss: 0.1244 - mean_iou: 0.7361 - val_loss: 0.1793 - val_mean_iou: 0.7379\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/80\n",
      "6400/6400 [==============================] - 974s 152ms/step - loss: 0.1223 - mean_iou: 0.7397 - val_loss: 0.1741 - val_mean_iou: 0.7414\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/80\n",
      "6400/6400 [==============================] - 1021s 160ms/step - loss: 0.1231 - mean_iou: 0.7432 - val_loss: 0.1816 - val_mean_iou: 0.7448\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/80\n",
      "6400/6400 [==============================] - 996s 156ms/step - loss: 0.1204 - mean_iou: 0.7464 - val_loss: 0.1742 - val_mean_iou: 0.7480\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "Epoch 32/80\n",
      "6400/6400 [==============================] - 990s 155ms/step - loss: 0.1196 - mean_iou: 0.7495 - val_loss: 0.1744 - val_mean_iou: 0.7510\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 33/80\n",
      "6400/6400 [==============================] - 995s 155ms/step - loss: 0.1196 - mean_iou: 0.7525 - val_loss: 0.1688 - val_mean_iou: 0.7538\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.17232 to 0.16878, saving model to ./keras.model\n",
      "Epoch 34/80\n",
      "6400/6400 [==============================] - 975s 152ms/step - loss: 0.1181 - mean_iou: 0.7552 - val_loss: 0.1888 - val_mean_iou: 0.7566\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "Epoch 35/80\n",
      "6400/6400 [==============================] - 1034s 162ms/step - loss: 0.1167 - mean_iou: 0.7579 - val_loss: 0.1880 - val_mean_iou: 0.7592\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/80\n",
      "6400/6400 [==============================] - 950s 148ms/step - loss: 0.1190 - mean_iou: 0.7604 - val_loss: 0.1762 - val_mean_iou: 0.7616\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "Epoch 37/80\n",
      "6400/6400 [==============================] - 1024s 160ms/step - loss: 0.1157 - mean_iou: 0.7628 - val_loss: 0.1755 - val_mean_iou: 0.7639\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 38/80\n",
      "6400/6400 [==============================] - 978s 153ms/step - loss: 0.1152 - mean_iou: 0.7651 - val_loss: 0.1775 - val_mean_iou: 0.7662\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 39/80\n",
      "6400/6400 [==============================] - 1094s 171ms/step - loss: 0.1141 - mean_iou: 0.7673 - val_loss: 0.1783 - val_mean_iou: 0.7684\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 40/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 1073s 168ms/step - loss: 0.1116 - mean_iou: 0.7694 - val_loss: 0.1794 - val_mean_iou: 0.7705\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 41/80\n",
      "2880/6400 [============>.................] - ETA: 8:58 - loss: 0.1088 - mean_iou: 0.7710"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-179-bca1852a16be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                     callbacks=[early_stopping, model_checkpoint, reduce_lr])\n\u001b[0m",
      "\u001b[0;32m/Users/tamiminaser/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Users/tamiminaser/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tamiminaser/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tamiminaser/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tamiminaser/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tamiminaser/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/tamiminaser/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tamiminaser/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience=10, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(\"./keras.model\", save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1)\n",
    "\n",
    "epochs = 80\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=[x_valid, y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[early_stopping, model_checkpoint, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(\"./keras.model\",custom_objects={'mean_iou': mean_iou})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_valid = model.predict(x_valid).reshape(-1, img_size_target, img_size_target)\n",
    "preds_valid = np.array([downsample(x) for x in preds_valid])\n",
    "y_valid = np.array([downsample(x) for x in y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766b39d49b494dde952bb9fa20537393"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "thresholds = np.linspace(0, 1, 50)\n",
    "ious = np.array([iou_metric_batch(y_valid, np.int32(preds_valid > threshold)) for threshold in tqdm_notebook(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold:  0.571428571429\n"
     ]
    }
   ],
   "source": [
    "threshold_best_index = np.argmax(ious[9:-10]) + 9\n",
    "iou_best = ious[threshold_best_index]\n",
    "threshold_best = thresholds[threshold_best_index]\n",
    "print('Best Threshold: ',threshold_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#threshold_best=6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Source https://www.kaggle.com/bguberfain/unet-with-depth\n",
    "def RLenc(img, order='F', format=True):\n",
    "    \"\"\"\n",
    "    img is binary mask image, shape (r,c)\n",
    "    order is down-then-right, i.e. Fortran\n",
    "    format determines if the order needs to be preformatted (according to submission rules) or not\n",
    "\n",
    "    returns run length as an array or string (if format is True)\n",
    "    \"\"\"\n",
    "    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n",
    "    runs = []  ## list of run lengths\n",
    "    r = 0  ## the current run length\n",
    "    pos = 1  ## count starts from 1 per WK\n",
    "    for c in bytes:\n",
    "        if (c == 0):\n",
    "            if r != 0:\n",
    "                runs.append((pos, r))\n",
    "                pos += r\n",
    "                r = 0\n",
    "            pos += 1\n",
    "        else:\n",
    "            r += 1\n",
    "\n",
    "    # if last run is unsaved (i.e. data ends with 1)\n",
    "    if r != 0:\n",
    "        runs.append((pos, r))\n",
    "        pos += r\n",
    "        r = 0\n",
    "\n",
    "    if format:\n",
    "        z = ''\n",
    "\n",
    "        for rr in runs:\n",
    "            z += '{} {} '.format(rr[0], rr[1])\n",
    "        return z[:-1]\n",
    "    else:\n",
    "        return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f07680bcbc31445f94d3461ce5da19ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_test = np.array([upsample(np.array(load_img(path=idx, grayscale=True))) / 255 for idx in tqdm_notebook(df_Test_path.Test_Image_path)]).reshape(-1, img_size_target, img_size_target, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a64f6fe756e47299fbebdb4b64e5d5b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_dict = {idx: RLenc(np.round(downsample(preds_test[i]) > threshold_best)) for i, idx in enumerate(tqdm_notebook(df_Test_path.id.values))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rle_mask</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155410d6fa</th>\n",
       "      <td>1 1007 1011 97 1112 96 1213 95 1314 94 1415 93...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78b32781d1</th>\n",
       "      <td>59 43 159 44 259 45 359 46 458 48 558 49 657 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63db2a476a</th>\n",
       "      <td>5956 3 6055 5 6154 8 6254 9 6354 10 6454 11 65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17bfcdb967</th>\n",
       "      <td>4547 43 4621 5 4639 7 4647 54 4714 5488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7ea0fd3c88</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     rle_mask\n",
       "id                                                           \n",
       "155410d6fa  1 1007 1011 97 1112 96 1213 95 1314 94 1415 93...\n",
       "78b32781d1  59 43 159 44 259 45 359 46 458 48 558 49 657 5...\n",
       "63db2a476a  5956 3 6055 5 6154 8 6254 9 6354 10 6454 11 65...\n",
       "17bfcdb967            4547 43 4621 5 4639 7 4647 54 4714 5488\n",
       "7ea0fd3c88                                                   "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
